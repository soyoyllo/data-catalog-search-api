import json
import logging
import os
from contextlib import asynccontextmanager
from typing import List, Dict, Optional
from pathlib import Path

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores.utils import DistanceStrategy

# --- ë¡œê¹… ì„¤ì • ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Pydantic ëª¨ë¸ ì •ì˜ (API ì…ì¶œë ¥ í˜•ì‹) ---

class QueryRequest(BaseModel):
    query: str

class ColumnDescription(BaseModel):
    column_name: str
    description: str
    data_type: str
    is_primary_key: bool

class TableSearchResult(BaseModel):
    # [ìˆ˜ì •] score -> similarity_scoreë¡œ ì´ë¦„ ë³€ê²½
    similarity_score: float
    table_name: str
    table_description: str
    # [ì¶”ê°€] OpenMetadata URL í•„ë“œ ì¶”ê°€
    openmetadata_url: str
    column_descriptions: List[ColumnDescription]

class SearchResponse(BaseModel):
    status: str
    original_query: str
    # [ì¶”ê°€] í–¥í›„ LLM ì‘ë‹µì„ ìœ„í•œ í•„ë“œ ì¶”ê°€
    llm_response: Optional[str] = None
    results: Optional[List[TableSearchResult]] = None

# --- ê²€ìƒ‰ ì—”ì§„ ë¡œì§ ---

def load_metadata(file_path: Path) -> List[Dict]:
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def create_and_save_faiss_index(metadata_list: List[Dict], index_path: Path, embedding_model: SentenceTransformerEmbeddings):
    """FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê³  íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    documents, metadatas = [], []
    for table in metadata_list:
        table_name = table['name']
        column_texts = [f"- ì»¬ëŸ¼ '{col['name']}': {col['description']}" for col in table.get('columns', [])]
        full_doc = f"í…Œì´ë¸”ëª…: {table_name}\ní…Œì´ë¸” ì„¤ëª…: {table['description']}\ní¬í•¨ëœ ì»¬ëŸ¼ ì •ë³´:\n" + "\n".join(column_texts)
        documents.append(full_doc)
        metadatas.append({"type": "table", "table_name": table_name})
    
    logger.info(f"ì´ {len(documents)}ê°œì˜ ë¬¸ì„œë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤...")
    embeddings = embedding_model.embed_documents(documents)
    
    text_embedding_pairs = list(zip(documents, embeddings))
    
    logger.info("ì½”ì‚¬ì¸ ê±°ë¦¬ ë°©ì‹ìœ¼ë¡œ ìƒˆë¡œìš´ FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
    vector_db = FAISS.from_embeddings(
        text_embeddings=text_embedding_pairs, 
        embedding=embedding_model, 
        metadatas=metadatas, 
        distance_strategy=DistanceStrategy.COSINE
    )
    
    vector_db.save_local(str(index_path))
    logger.info(f"âœ… ìƒˆë¡œìš´ ì¸ë±ìŠ¤ë¥¼ '{index_path}' íŒŒì¼ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    return vector_db

# [ìˆ˜ì •] OpenMetadata URLì„ ì¸ìë¡œ ë°›ì•„ ìµœì¢… ê²°ê³¼ë¥¼ ìƒì„±í•˜ë„ë¡ ë³€ê²½
def search_and_format_results(query: str, vector_db: FAISS, all_metadata_dict: Dict, openmetadata_base_url: str, top_k: int = 3) -> Optional[List[Dict]]:
    """ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ìƒì„¸í•œ JSON í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”í•©ë‹ˆë‹¤."""
    similar_docs = vector_db.similarity_search_with_score(query, k=top_k)
    
    logger.info(f"ğŸ” ë²¡í„° DB ê²€ìƒ‰ ê²°ê³¼ (Top {top_k}):")
    for i, (doc, score) in enumerate(similar_docs):
        log_content = doc.page_content.replace('\n', ' ')
        logger.info(f"  - [{i+1}] ìœ ì‚¬ë„ ì ìˆ˜(ì½”ì‚¬ì¸ ê±°ë¦¬): {score:.4f}, ë‚´ìš©: \"{log_content[:80]}...\"")

    if not similar_docs: return None
    
    found_tables = {}
    threshold = 0.5
    for doc, score in similar_docs:
        table_name = doc.metadata['table_name']
        if score < threshold:
            if table_name not in found_tables or score < found_tables[table_name]:
                found_tables[table_name] = score
                logger.info(f"    -> âœ… ì„ê³„ê°’ í†µê³¼. í…Œì´ë¸” '{table_name}' ì¶”ê°€/ê°±ì‹  (ì ìˆ˜: {score:.4f}).")

    if not found_tables and similar_docs:
        top_doc, top_score = similar_docs[0]
        table_name = top_doc.metadata['table_name']
        found_tables[table_name] = top_score
        logger.info(f"    -> âš ï¸ ì„ê³„ê°’ í†µê³¼ ê²°ê³¼ ì—†ìŒ. ê°€ì¥ ìœ ì‚¬í•œ '{table_name}'ì„(ë¥¼) ëŒ€ì‹  ë°˜í™˜í•©ë‹ˆë‹¤.")

    results_list = []
    for table_name, score in sorted(found_tables.items(), key=lambda item: item[1]):
        table_data = all_metadata_dict.get(table_name)
        if table_data:
            results_list.append({
                "similarity_score": round(score, 4),
                "table_name": table_name,
                "table_description": table_data['description'],
                "openmetadata_url": f"{openmetadata_base_url}/explore/?search={table_name}&sort=_score&page=1&size=15",
                "column_descriptions": [
                    {
                        "column_name": col['name'], 
                        "description": col['description'],
                        "data_type": col.get('dataTypeDisplay', 'N/A'),
                        "is_primary_key": col.get('isPrimaryKey', False)
                    } 
                    for col in table_data.get('columns', [])
                ]
            })
    return results_list

# --- FastAPI ì•± ìƒëª…ì£¼ê¸° ë° ì „ì—­ ë³€ìˆ˜ ì„¤ì • ---
search_engine_globals = {}

@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("ğŸš€ ì„œë²„ ì‹œì‘: ê²€ìƒ‰ ì—”ì§„ì„ ì„¤ì •í•©ë‹ˆë‹¤...")
    
    # [ì¶”ê°€] í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenMetadata URLì„ ì½ì–´ì˜µë‹ˆë‹¤.
    OPENMETADATA_BASE_URL = os.getenv("OPENMETADATA_BASE_URL", "https://de4f5334deb3.ngrok-free.app/my-data")
    search_engine_globals['openmetadata_base_url'] = OPENMETADATA_BASE_URL
    logger.info(f"OpenMetadata ê¸°ë³¸ URL: {OPENMETADATA_BASE_URL}")

    METADATA_FILE_PATH = Path('metadata/enriched_metadata_clustered.json')
    FAISS_INDEX_PATH = Path("faiss_indices/faiss_index_e5_small") 

    all_metadata = load_metadata(METADATA_FILE_PATH)
    search_engine_globals['metadata_dict'] = {table['name']: table for table in all_metadata}
    
    logger.info("E5-Small ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
    embedding_model = SentenceTransformerEmbeddings(
        model_name="intfloat/multilingual-e5-small"
    )
    
    if not FAISS_INDEX_PATH.exists():
        FAISS_INDEX_PATH.parent.mkdir(parents=True, exist_ok=True)
        logger.warning(f"ì¸ë±ìŠ¤ íŒŒì¼ '{FAISS_INDEX_PATH}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        create_and_save_faiss_index(all_metadata, FAISS_INDEX_PATH, embedding_model)
    
    logger.info(f"'{FAISS_INDEX_PATH}'ì—ì„œ ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
    search_engine_globals['vector_db'] = FAISS.load_local(
        str(FAISS_INDEX_PATH), 
        embedding_model, 
        allow_dangerous_deserialization=True,
        distance_strategy=DistanceStrategy.COSINE 
    )
    
    logger.info("âœ… ê²€ìƒ‰ ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ.")
    yield
    search_engine_globals.clear()
    logger.info("ğŸ‘‹ ì„œë²„ ì¢…ë£Œ.")

# --- FastAPI ì•± ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ---
app = FastAPI(
    title="ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ API (E5-small)",
    description="ìì—°ì–´ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í…Œì´ë¸” ë° ì»¬ëŸ¼ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.",
    version="2.8", # ë²„ì „ ì—…ë°ì´íŠ¸
    lifespan=lifespan
)

# --- API ì—”ë“œí¬ì¸íŠ¸ ---
@app.post("/search", response_model=SearchResponse)
async def search_metadata(request: QueryRequest):
    query = request.query
    logger.info(f"ğŸ“¬ ìˆ˜ì‹ ëœ ì¿¼ë¦¬: {query}")
    vector_db = search_engine_globals.get('vector_db')
    metadata_dict = search_engine_globals.get('metadata_dict')
    openmetadata_base_url = search_engine_globals.get('openmetadata_base_url')

    if not all([vector_db, metadata_dict, openmetadata_base_url]):
        raise HTTPException(status_code=503, detail="ê²€ìƒ‰ ì—”ì§„ì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
    try:
        search_results = search_and_format_results(query, vector_db, metadata_dict, openmetadata_base_url)
        return SearchResponse(
            status="success", 
            original_query=query, 
            # [ì¶”ê°€] llm_response í•„ë“œì— ê¸°ë³¸ê°’ ì¶”ê°€
            llm_response="LLM ì‘ë‹µì€ í–¥í›„ ì¶”ê°€ë  ì˜ˆì •ì…ë‹ˆë‹¤.",
            results=search_results
        )
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="ê²€ìƒ‰ ì²˜ë¦¬ ì¤‘ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

